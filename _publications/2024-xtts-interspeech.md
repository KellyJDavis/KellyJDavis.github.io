---
title: "XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model"
collection: publications
category: conferences
permalink: /publication/2024-xtts-interspeech
excerpt: 'XTTS enables multilingual zero-shot TTS in 16 languages with state-of-the-art results, building on Tortoise with novel modifications for multilingual training, improved voice cloning, and faster training and inference.'
date: 2024-01-01
venue: 'INTERSPEECH 2024'
paperurl: 'https://arxiv.org/abs/2406.04904'
citation: 'Edresson Casanova, Kelly Davis, Eren Gölge, Görkem Göknar, Iulian Gulea, Logan Hart, Aya Aljafari, Joshua Meyer, Reuben Morais, Samuel Olayemi, Julian Weber. (2024). &quot;XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model.&quot; <i>INTERSPEECH 2024</i>.'
---

Most Zero-shot Multi-speaker TTS (ZS-TTS) systems support only a single language. Although models like YourTTS, VALL-E X, Mega-TTS 2, and Voicebox explored Multilingual ZS-TTS they are limited to just a few high/medium resource languages. We propose and make publicly available the XTTS system, which builds upon the Tortoise model with several novel modifications to enable multilingual training, improve voice cloning, and enable faster training and inference. XTTS was trained in 16 languages and achieved state-of-the-art results in most of them.
